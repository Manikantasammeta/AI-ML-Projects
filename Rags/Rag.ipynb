{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b03b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee805c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Rama was the eldest son of King Dasharatha of\n",
      "Ayodhya and Queen Kaushalya. \n",
      "He was known for his virtue, strength, and\n",
      "righteousness. Dasharatha had three wives: Kaushalya,\n",
      "Kaikeyi, and Sumitra. \n",
      "Rama had three brothers: Bharata, Lakshmana, and\n",
      "Shatrughna. Among them, Rama and Lakshmana were\n",
      "especially close.\n",
      "One day, the sage Vishwamitra came to Ayodhya and\n",
      "asked for Rama’s help to defeat demons that were\n",
      "disturbing his rituals. \n",
      "Rama and Lakshmana went with him, and they defeated\n",
      "the demons with great courage. On their way back,\n",
      "they passed through the kingdom of Mithila, \n",
      "where King Janaka had arranged a swayamvara for his\n",
      "daughter, Sita. Rama broke the bow of Lord Shiva and\n",
      "won Sita’s hand in marriage.\n",
      "Rama and Sita returned to Ayodhya and lived happily.\n",
      "However, Dasharatha’s second wife Kaikeyi demanded\n",
      "that her son Bharata be made king, \n",
      "and Rama be exiled for 14 years. Obeying his father’s\n",
      "promise, Rama went into the forest with Sita and\n",
      "Lakshmana.\n",
      "In the forest, they faced many challenges. One day,\n",
      "the demoness Shurpanakha tried to attack Sita, and\n",
      "Lakshmana cut off her nose. \n",
      "Enraged, she went to her brother Ravana, the mighty\n",
      "king of Lanka. Ravana kidnapped Sita and took her to\n",
      "Lanka.\n",
      "Rama, with the help of the monkey king Sugriva and\n",
      "the mighty Hanuman, built an army to rescue Sita.\n",
      "Hanuman flew to Lanka, found Sita in Ashok Vatika, \n",
      "and gave her Rama’s ring. Rama’s army built a bridge\n",
      "over the ocean to reach Lanka. A fierce battle\n",
      "followed, and Rama finally defeated Ravana and\n",
      "rescued Sita.\n",
      "Rama, Sita, and Lakshmana returned to Ayodhya, and\n",
      "Rama was crowned king. His rule, known as Ram Rajya,\n",
      "was a time of peace and prosperity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def load_pdf_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        full_text += page.get_text()\n",
    "    return full_text\n",
    "pdf_path = \"rama_story.txt\"\n",
    "raw_text = load_pdf_text(pdf_path)\n",
    "print(raw_text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de4608a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Rama was the eldest son of King Dasharatha of Ayodhya and Queen Kaushalya. He was known for his virtue, strength, and righteousness. Dasharatha had three wives: Kaushalya, Kaikeyi, and Sumitra. Rama had three brothers: Bharata, Lakshmana, and Shatrughna. Among them, Rama and Lakshmana were especially close. One day, the sage Vishwamitra came to Ayodhya and asked for Ramas help to defeat demons that were disturbing his rituals. Rama and Lakshmana went with him, and they defeated the demons with great courage. On their way back, they passed through the kingdom of Mithila, where King Janaka had arranged a swayamvara for his daughter, Sita. Rama broke the bow of Lord Shiva and won Sitas hand in marriage. Rama and Sita returned to Ayodhya and lived happily. However, Dasharathas second wife Kaikeyi demanded that her son Bharata be made king, and Rama be exiled for 14 years. Obeying his fathers promise, Rama went into the forest with Sita and Lakshmana. In the forest, they faced many challenges. One day, the demoness Shurpanakha tried to attack Sita, and Lakshmana cut off her nose. Enraged, she went to her brother Ravana, the mighty king of Lanka. Ravana kidnapped Sita and took her to Lanka. Rama, with the help of the monkey king Sugriva and the mighty Hanuman, built an army to rescue Sita. Hanuman flew to Lanka, found Sita in Ashok Vatika, and gave her Ramas ring. Ramas army built a bridge over the ocean to reach Lanka. A fierce battle followed, and Rama finally defeated Ravana and rescued Sita. Rama, Sita, and Lakshmana returned to Ayodhya, and Rama was crowned king. His rule, known as Ram Rajya, was a time of peace and prosperity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')  # Required for sent_tokenize to work\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    import re\n",
    "    text = re.sub(r'[\\n\\r\\t]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9.,;:!?()\\[\\]\\'\" -]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "clean_sentences = preprocess_text(raw_text)\n",
    "\n",
    "print(clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5068c9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L o r d   R a m a   w a s   t h e   e l d e s t   s o n   o f   K i n g   D a s h a r a t h a   o f   A y o d h y a   a n d   Q u e e n   K a u s h a l y a .   H e   w a s   k n o w n   f o r   h i s   v i r t u e ,   s t r e n g t h ,   a n d   r i g h t e o u s n e s s .   D a s h a r a t h a   h a d   t h r e e   w i v e s :   K a u s h a l y a ,   K', '  w i v e s :   K a u s h a l y a ,   K a i k e y i ,   a n d   S u m i t r a .   R a m a   h a d   t h r e e   b r o t h e r s :   B h a r a t a ,   L a k s h m a n a ,   a n d   S h a t r u g h n a .   A m o n g   t h e m ,   R a m a   a n d   L a k s h m a n a   w e r e   e s p e c i a l l y   c l o s e .   O n e   d a y ,   t h e   s a g e   V i', 'O n e   d a y ,   t h e   s a g e   V i s h w a m i t r a   c a m e   t o   A y o d h y a   a n d   a s k e d   f o r   R a m a s   h e l p   t o   d e f e a t   d e m o n s   t h a t   w e r e   d i s t u r b i n g   h i s   r i t u a l s .   R a m a   a n d   L a k s h m a n a   w e n t   w i t h   h i m ,   a n d   t h e y   d e f e a t e d   t h e   d e m', 'h e y   d e f e a t e d   t h e   d e m o n s   w i t h   g r e a t   c o u r a g e .   O n   t h e i r   w a y   b a c k ,   t h e y   p a s s e d   t h r o u g h   t h e   k i n g d o m   o f   M i t h i l a ,   w h e r e   K i n g   J a n a k a   h a d   a r r a n g e d   a   s w a y a m v a r a   f o r   h i s   d a u g h t e r ,   S i t a .   R a m a  ', 'a u g h t e r ,   S i t a .   R a m a   b r o k e   t h e   b o w   o f   L o r d   S h i v a   a n d   w o n   S i t a s   h a n d   i n   m a r r i a g e .   R a m a   a n d   S i t a   r e t u r n e d   t o   A y o d h y a   a n d   l i v e d   h a p p i l y .   H o w e v e r ,   D a s h a r a t h a s   s e c o n d   w i f e   K a i k e y i   d e m a n', 'd   w i f e   K a i k e y i   d e m a n d e d   t h a t   h e r   s o n   B h a r a t a   b e   m a d e   k i n g ,   a n d   R a m a   b e   e x i l e d   f o r   1 4   y e a r s .   O b e y i n g   h i s   f a t h e r s   p r o m i s e ,   R a m a   w e n t   i n t o   t h e   f o r e s t   w i t h   S i t a   a n d   L a k s h m a n a .   I n   t h e   f o r e', 'k s h m a n a .   I n   t h e   f o r e s t ,   t h e y   f a c e d   m a n y   c h a l l e n g e s .   O n e   d a y ,   t h e   d e m o n e s s   S h u r p a n a k h a   t r i e d   t o   a t t a c k   S i t a ,   a n d   L a k s h m a n a   c u t   o f f   h e r   n o s e .   E n r a g e d ,   s h e   w e n t   t o   h e r   b r o t h e r   R a v a n a', 'o   h e r   b r o t h e r   R a v a n a ,   t h e   m i g h t y   k i n g   o f   L a n k a .   R a v a n a   k i d n a p p e d   S i t a   a n d   t o o k   h e r   t o   L a n k a .   R a m a ,   w i t h   t h e   h e l p   o f   t h e   m o n k e y   k i n g   S u g r i v a   a n d   t h e   m i g h t y   H a n u m a n ,   b u i l t   a n   a r m y   t o   r e s', 'b u i l t   a n   a r m y   t o   r e s c u e   S i t a .   H a n u m a n   f l e w   t o   L a n k a ,   f o u n d   S i t a   i n   A s h o k   V a t i k a ,   a n d   g a v e   h e r   R a m a s   r i n g .   R a m a s   a r m y   b u i l t   a   b r i d g e   o v e r   t h e   o c e a n   t o   r e a c h   L a n k a .   A   f i e r c e   b a t t l e   f o l l o', '  f i e r c e   b a t t l e   f o l l o w e d ,   a n d   R a m a   f i n a l l y   d e f e a t e d   R a v a n a   a n d   r e s c u e d   S i t a .   R a m a ,   S i t a ,   a n d   L a k s h m a n a   r e t u r n e d   t o   A y o d h y a ,   a n d   R a m a   w a s   c r o w n e d   k i n g .   H i s   r u l e ,   k n o w n   a s   R a m   R a j y a ,  ', 'k n o w n   a s   R a m   R a j y a ,   w a s   a   t i m e   o f   p e a c e   a n d   p r o s p e r i t y .']\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(sentences, chunk_size=150, overlap=20):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence.split())\n",
    "\n",
    "        if current_length + sentence_length > chunk_size:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = current_chunk[-overlap:]  # keep overlap\n",
    "            current_length = sum(len(s.split()) for s in current_chunk)\n",
    "\n",
    "        current_chunk.append(sentence)\n",
    "        current_length += sentence_length\n",
    "\n",
    "    # Add final chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "print(chunk_text(clean_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3219725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 11\n",
      "Embedding dimension: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def get_embeddings(chunks):\n",
    "    embeddings = embedding_model.encode(chunks, show_progress_bar=True)\n",
    "    return embeddings\n",
    "chunks = chunk_text(clean_sentences)\n",
    "embeddings = get_embeddings(chunks)\n",
    "\n",
    "# Check shape\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fee1d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def store_embeddings_faiss(embeddings):\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings.astype('float32'))\n",
    "    return index\n",
    "\n",
    "# Convert embeddings to numpy if needed\n",
    "embeddings_np = np.array(embeddings).astype('float32')\n",
    "\n",
    "# Create FAISS index\n",
    "index = store_embeddings_faiss(embeddings_np)\n",
    "\n",
    "\n",
    "\n",
    "# Save chunks in order (in memory or file)\n",
    "with open(\"chunk_texts.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for chunk in chunks:\n",
    "        f.write(chunk.replace(\"\\n\", \" \") + \"\\n\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ce3de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\manik\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3cbf1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_with_context(query, context_chunks):\n",
    "    context = \"\\n\".join(context_chunks)\n",
    "    prompt = f\"\"\"Answer the question based on the context below:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "    \n",
    "    # Generate output\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200)\n",
    "    \n",
    "    # Decode answer\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8ca696a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_similar_chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mWho is Rama?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Retrieve top-k chunks\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m top_chunks = \u001b[43msearch_similar_chunks\u001b[49m(query, index, chunks, embedding_model)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Generate the answer\u001b[39;00m\n\u001b[32m      8\u001b[39m answer = generate_answer_with_context(query, top_chunks)\n",
      "\u001b[31mNameError\u001b[39m: name 'search_similar_chunks' is not defined"
     ]
    }
   ],
   "source": [
    "# Define your query\n",
    "query = \"Who is Rama?\"\n",
    "\n",
    "# Retrieve top-k chunks\n",
    "top_chunks = search_similar_chunks(query, index, chunks, embedding_model)\n",
    "\n",
    "# Generate the answer\n",
    "answer = generate_answer_with_context(query, top_chunks)\n",
    "\n",
    "# Print it\n",
    "print(\"Answer:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
