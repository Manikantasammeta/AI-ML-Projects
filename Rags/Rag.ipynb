{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b03b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee805c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Rama was the eldest son of King Dasharatha of\n",
      "Ayodhya and Queen Kaushalya. \n",
      "He was known for his virtue, strength, and\n",
      "righteousness. Dasharatha had three wives: Kaushalya,\n",
      "Kaikeyi, and Sumitra. \n",
      "Rama had three brothers: Bharata, Lakshmana, and\n",
      "Shatrughna. Among them, Rama and Lakshmana were\n",
      "especially close.\n",
      "One day, the sage Vishwamitra came to Ayodhya and\n",
      "asked for Rama’s help to defeat demons that were\n",
      "disturbing his rituals. \n",
      "Rama and Lakshmana went with him, and they defeated\n",
      "the demons with great courage. On their way back,\n",
      "they passed through the kingdom of Mithila, \n",
      "where King Janaka had arranged a swayamvara for his\n",
      "daughter, Sita. Rama broke the bow of Lord Shiva and\n",
      "won Sita’s hand in marriage.\n",
      "Rama and Sita returned to Ayodhya and lived happily.\n",
      "However, Dasharatha’s second wife Kaikeyi demanded\n",
      "that her son Bharata be made king, \n",
      "and Rama be exiled for 14 years. Obeying his father’s\n",
      "promise, Rama went into the forest with Sita and\n",
      "Lakshmana.\n",
      "In the forest, they faced many challenges. One day,\n",
      "the demoness Shurpanakha tried to attack Sita, and\n",
      "Lakshmana cut off her nose. \n",
      "Enraged, she went to her brother Ravana, the mighty\n",
      "king of Lanka. Ravana kidnapped Sita and took her to\n",
      "Lanka.\n",
      "Rama, with the help of the monkey king Sugriva and\n",
      "the mighty Hanuman, built an army to rescue Sita.\n",
      "Hanuman flew to Lanka, found Sita in Ashok Vatika, \n",
      "and gave her Rama’s ring. Rama’s army built a bridge\n",
      "over the ocean to reach Lanka. A fierce battle\n",
      "followed, and Rama finally defeated Ravana and\n",
      "rescued Sita.\n",
      "Rama, Sita, and Lakshmana returned to Ayodhya, and\n",
      "Rama was crowned king. His rule, known as Ram Rajya,\n",
      "was a time of peace and prosperity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def load_pdf_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        full_text += page.get_text()\n",
    "    return full_text\n",
    "pdf_path = \"rama_story.txt\"\n",
    "raw_text = load_pdf_text(pdf_path)\n",
    "print(raw_text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de4608a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manik\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Rama was the eldest son of King Dasharatha of Ayodhya and Queen Kaushalya. He was known for his virtue, strength, and righteousness. Dasharatha had three wives: Kaushalya, Kaikeyi, and Sumitra. Rama had three brothers: Bharata, Lakshmana, and Shatrughna. Among them, Rama and Lakshmana were especially close. One day, the sage Vishwamitra came to Ayodhya and asked for Ramas help to defeat demons that were disturbing his rituals. Rama and Lakshmana went with him, and they defeated the demons with great courage. On their way back, they passed through the kingdom of Mithila, where King Janaka had arranged a swayamvara for his daughter, Sita. Rama broke the bow of Lord Shiva and won Sitas hand in marriage. Rama and Sita returned to Ayodhya and lived happily. However, Dasharathas second wife Kaikeyi demanded that her son Bharata be made king, and Rama be exiled for 14 years. Obeying his fathers promise, Rama went into the forest with Sita and Lakshmana. In the forest, they faced many challenges. One day, the demoness Shurpanakha tried to attack Sita, and Lakshmana cut off her nose. Enraged, she went to her brother Ravana, the mighty king of Lanka. Ravana kidnapped Sita and took her to Lanka. Rama, with the help of the monkey king Sugriva and the mighty Hanuman, built an army to rescue Sita. Hanuman flew to Lanka, found Sita in Ashok Vatika, and gave her Ramas ring. Ramas army built a bridge over the ocean to reach Lanka. A fierce battle followed, and Rama finally defeated Ravana and rescued Sita. Rama, Sita, and Lakshmana returned to Ayodhya, and Rama was crowned king. His rule, known as Ram Rajya, was a time of peace and prosperity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')  # Required for sent_tokenize to work\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    import re\n",
    "    text = re.sub(r'[\\n\\r\\t]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9.,;:!?()\\[\\]\\'\" -]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "clean_sentences = preprocess_text(raw_text)\n",
    "\n",
    "print(clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5068c9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L o r d   R a m a   w a s   t h e   e l d e s t   s o n   o f   K i n g   D a s h a r a t h a   o f   A y o d h y a   a n d   Q u e e n   K a u s h a l y a .   H e   w a s   k n o w n   f o r   h i s   v i r t u e ,   s t r e n g t h ,   a n d   r i g h t e o u s n e s s .   D a s h a r a t h a   h a d   t h r e e   w i v e s :   K a u s h a l y a ,   K', '  w i v e s :   K a u s h a l y a ,   K a i k e y i ,   a n d   S u m i t r a .   R a m a   h a d   t h r e e   b r o t h e r s :   B h a r a t a ,   L a k s h m a n a ,   a n d   S h a t r u g h n a .   A m o n g   t h e m ,   R a m a   a n d   L a k s h m a n a   w e r e   e s p e c i a l l y   c l o s e .   O n e   d a y ,   t h e   s a g e   V i', 'O n e   d a y ,   t h e   s a g e   V i s h w a m i t r a   c a m e   t o   A y o d h y a   a n d   a s k e d   f o r   R a m a s   h e l p   t o   d e f e a t   d e m o n s   t h a t   w e r e   d i s t u r b i n g   h i s   r i t u a l s .   R a m a   a n d   L a k s h m a n a   w e n t   w i t h   h i m ,   a n d   t h e y   d e f e a t e d   t h e   d e m', 'h e y   d e f e a t e d   t h e   d e m o n s   w i t h   g r e a t   c o u r a g e .   O n   t h e i r   w a y   b a c k ,   t h e y   p a s s e d   t h r o u g h   t h e   k i n g d o m   o f   M i t h i l a ,   w h e r e   K i n g   J a n a k a   h a d   a r r a n g e d   a   s w a y a m v a r a   f o r   h i s   d a u g h t e r ,   S i t a .   R a m a  ', 'a u g h t e r ,   S i t a .   R a m a   b r o k e   t h e   b o w   o f   L o r d   S h i v a   a n d   w o n   S i t a s   h a n d   i n   m a r r i a g e .   R a m a   a n d   S i t a   r e t u r n e d   t o   A y o d h y a   a n d   l i v e d   h a p p i l y .   H o w e v e r ,   D a s h a r a t h a s   s e c o n d   w i f e   K a i k e y i   d e m a n', 'd   w i f e   K a i k e y i   d e m a n d e d   t h a t   h e r   s o n   B h a r a t a   b e   m a d e   k i n g ,   a n d   R a m a   b e   e x i l e d   f o r   1 4   y e a r s .   O b e y i n g   h i s   f a t h e r s   p r o m i s e ,   R a m a   w e n t   i n t o   t h e   f o r e s t   w i t h   S i t a   a n d   L a k s h m a n a .   I n   t h e   f o r e', 'k s h m a n a .   I n   t h e   f o r e s t ,   t h e y   f a c e d   m a n y   c h a l l e n g e s .   O n e   d a y ,   t h e   d e m o n e s s   S h u r p a n a k h a   t r i e d   t o   a t t a c k   S i t a ,   a n d   L a k s h m a n a   c u t   o f f   h e r   n o s e .   E n r a g e d ,   s h e   w e n t   t o   h e r   b r o t h e r   R a v a n a', 'o   h e r   b r o t h e r   R a v a n a ,   t h e   m i g h t y   k i n g   o f   L a n k a .   R a v a n a   k i d n a p p e d   S i t a   a n d   t o o k   h e r   t o   L a n k a .   R a m a ,   w i t h   t h e   h e l p   o f   t h e   m o n k e y   k i n g   S u g r i v a   a n d   t h e   m i g h t y   H a n u m a n ,   b u i l t   a n   a r m y   t o   r e s', 'b u i l t   a n   a r m y   t o   r e s c u e   S i t a .   H a n u m a n   f l e w   t o   L a n k a ,   f o u n d   S i t a   i n   A s h o k   V a t i k a ,   a n d   g a v e   h e r   R a m a s   r i n g .   R a m a s   a r m y   b u i l t   a   b r i d g e   o v e r   t h e   o c e a n   t o   r e a c h   L a n k a .   A   f i e r c e   b a t t l e   f o l l o', '  f i e r c e   b a t t l e   f o l l o w e d ,   a n d   R a m a   f i n a l l y   d e f e a t e d   R a v a n a   a n d   r e s c u e d   S i t a .   R a m a ,   S i t a ,   a n d   L a k s h m a n a   r e t u r n e d   t o   A y o d h y a ,   a n d   R a m a   w a s   c r o w n e d   k i n g .   H i s   r u l e ,   k n o w n   a s   R a m   R a j y a ,  ', 'k n o w n   a s   R a m   R a j y a ,   w a s   a   t i m e   o f   p e a c e   a n d   p r o s p e r i t y .']\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(sentences, chunk_size=150, overlap=20):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence.split())\n",
    "\n",
    "        if current_length + sentence_length > chunk_size:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = current_chunk[-overlap:]  # keep overlap\n",
    "            current_length = sum(len(s.split()) for s in current_chunk)\n",
    "\n",
    "        current_chunk.append(sentence)\n",
    "        current_length += sentence_length\n",
    "\n",
    "    # Add final chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "print(chunk_text(clean_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3219725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 11\n",
      "Embedding dimension: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def get_embeddings(chunks):\n",
    "    embeddings = embedding_model.encode(chunks, show_progress_bar=True)\n",
    "    return embeddings\n",
    "chunks = chunk_text(clean_sentences)\n",
    "embeddings = get_embeddings(chunks)\n",
    "\n",
    "# Check shape\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fee1d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def store_embeddings_faiss(embeddings):\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings.astype('float32'))\n",
    "    return index\n",
    "\n",
    "# Convert embeddings to numpy if needed\n",
    "embeddings_np = np.array(embeddings).astype('float32')\n",
    "\n",
    "# Create FAISS index\n",
    "index = store_embeddings_faiss(embeddings_np)\n",
    "\n",
    "\n",
    "\n",
    "# Save chunks in order (in memory or file)\n",
    "with open(\"chunk_texts.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for chunk in chunks:\n",
    "        f.write(chunk.replace(\"\\n\", \" \") + \"\\n\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9849ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini's Answer:\n",
      "Error from Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 43\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c8f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "]\n",
      "Retrying after 60 seconds...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Set API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCsRR4blOUdzCqucCg0G5VcrvoI81k1teg\"\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# ✅ Function to search top-k similar chunks\n",
    "def search_chunks(query, model, index, chunks, k=1):\n",
    "    query_embedding = model.encode([query]).astype('float32')\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    results = [chunks[i] for i in indices[0]]\n",
    "    return results\n",
    "\n",
    "# ✅ Function to call Gemini with context and retry on failure\n",
    "def ask_gemini_with_context(query, context_chunks):\n",
    "    context = \"\\n\\n\".join(context_chunks)\n",
    "    prompt = f\"\"\"Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Gemini Error: {e}\")\n",
    "        print(\"Retrying after 60 seconds...\")\n",
    "        time.sleep(60)\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"Failed again: {e}\"\n",
    "\n",
    "# ✅ Example usage\n",
    "\n",
    "# Your query\n",
    "query = \"Who is Rama?\"\n",
    "\n",
    "# Make sure the following are defined before running:\n",
    "# - embedding_model : your SentenceTransformer model\n",
    "# - index : FAISS index\n",
    "# - chunks : list of text chunks\n",
    "\n",
    "# Example (run these if not already done):\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import faiss\n",
    "# embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# embeddings = embedding_model.encode(chunks).astype('float32')\n",
    "# index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "# index.add(embeddings)\n",
    "\n",
    "# Step 1: Search top chunks\n",
    "top_chunks = search_chunks(query, embedding_model, index, chunks)\n",
    "\n",
    "# Step 2: Ask Gemini\n",
    "response = ask_gemini_with_context(query, top_chunks)\n",
    "\n",
    "# Output\n",
    "print(\"Gemini's Answer:\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
